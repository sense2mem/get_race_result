#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Ÿè¡Œæ—¥ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰ã®ãƒœãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹æ‰•æˆ»çµæœã‚’å–å¾—ã—ã¦ JSON ä¿å­˜
usage:
    python get_today_results.py            # â† å½“æ—¥ã‚’è‡ªå‹•åˆ¤å®š
    python get_today_results.py 20250805   # â† ä»»æ„ã®æ—¥ä»˜ã‚’æŒ‡å®šï¼ˆYYYYMMDDï¼‰
"""
import requests
from bs4 import BeautifulSoup
import time
import json
import re
import sys
from datetime import datetime, timedelta, timezone

JST = timezone(timedelta(hours=9))  # æ—¥æœ¬æ¨™æº–æ™‚

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  æ‰•æˆ»å–å¾—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_race_result(date_str: str, place_code: str, race_num: str):
    url = f"https://www.boatrace.jp/owpc/pc/race/raceresult?rno={race_num}&jcd={place_code}&hd={date_str}"
    try:
        res = requests.get(url, timeout=(5, 30))
        res.raise_for_status()
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")

        result = {"race_num": race_num, "payouts": {}}

        # å„ªå…ˆï¼šis-payout
        section = soup.find("div", class_="table1 is-payout")
        # ä»£æ›¿æ¢ç´¢
        if not section:
            for div in soup.find_all("div", class_="table1"):
                if re.search(r"å˜å‹|è¤‡å‹|2é€£å˜|3é€£è¤‡", div.get_text()):
                    section = div
                    break

        if not section:
            print(f"    â†’ æ‰•æˆ»æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {place_code} {race_num}R")
            return None

        for row in section.find_all("tr"):
            cols = [td.get_text(strip=True) for td in row.find_all("td")]
            if len(cols) < 3:
                continue
            bet_type, combo, payout = cols[0], cols[1], cols[2].replace(",", "")
            if bet_type in ["å˜å‹", "è¤‡å‹", "2é€£å˜", "2é€£è¤‡", "3é€£å˜", "3é€£è¤‡", "æ‹¡é€£è¤‡"]:
                result["payouts"].setdefault(bet_type, []).append(
                    {"combination": combo, "payout": payout}
                )

        return result if result["payouts"] else None

    except Exception as e:
        print(f"    â†’ ã‚¨ãƒ©ãƒ¼å–å¾—ä¸­: {e}")
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  é–‹å‚¬å ´ãƒ»Rç•ªå·ä¸€è¦§å–å¾—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_race_list_for_date(date_str: str):
    url = f"https://www.boatrace.jp/owpc/pc/race/index?hd={date_str}"
    resp = requests.get(url, timeout=(5, 30))
    resp.raise_for_status()
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")
    races = []
    for tbody in soup.select("div.table1 tbody"):
        img = tbody.find("img")
        a = tbody.find("a", href=lambda h: h and "raceindex" in h)
        if img and a:
            code = a["href"].split("jcd=")[1].split("&")[0]
            races.append({"date": date_str, "place_code": code, "place_name": img.get("alt", "")})
    return races


def get_races_for_place(date_str: str, place_code: str):
    url = f"https://www.boatrace.jp/owpc/pc/race/raceindex?jcd={place_code}&hd={date_str}"
    resp = requests.get(url, timeout=(5, 30))
    resp.raise_for_status()
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")
    return [td.get_text(strip=True).replace("R", "") for td in soup.select("div.table1 td.is-fBold a")]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ãƒ¡ã‚¤ãƒ³å‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # 1) æ—¥ä»˜æ±ºå®šï¼ˆå¼•æ•° > ä»Šæ—¥[JST] ã®é †ï¼‰
    if len(sys.argv) > 1:
        target_date = sys.argv[1]
    else:
        target_date = datetime.now(JST).strftime("%Y%m%d")

    output_file = f"race_results_{target_date}.json"
    all_results = []

    places = get_race_list_for_date(target_date)
    if not places:
        print(f"âŒ {target_date} ã¯é–‹å‚¬å ´ãªã—ï¼ˆã¾ãŸã¯æœªç¢ºå®šï¼‰")
        return

    for place in places:
        print(f"\nğŸŸï¸ {place['place_name']}({place['place_code']}) èª¿æŸ»ä¸­...")
        nums = get_races_for_place(target_date, place["place_code"])
        if not nums:
            print("    â†’ æœªé–‹å‚¬ã‚¹ã‚­ãƒƒãƒ—")
            continue

        skip_remaining = False
        for rn in nums:
            if skip_remaining:
                print(f"    ğŸš« {rn}R ã‚¹ã‚­ãƒƒãƒ—(1Rå¤±æ•—)")
                continue

            print(f"    ğŸ” {rn}R çµæœå–å¾—ä¸­...")
            res = get_race_result(target_date, place["place_code"], rn)
            if res:
                res.update(place)
                all_results.append(res)
            else:
                if rn == "1":
                    print("    âš ï¸ 1R æ‰•æˆ»å¤±æ•—ã®ãŸã‚æ®‹ã‚Šã‚¹ã‚­ãƒƒãƒ—")
                    skip_remaining = True
            time.sleep(1)  # polite crawling

    if all_results:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ä¿å­˜å®Œäº†: {output_file}")
    else:
        print("âš ï¸ æœ‰åŠ¹ãªæ‰•æˆ»ãƒ‡ãƒ¼ã‚¿ãªã—")


if __name__ == "__main__":
    main()
